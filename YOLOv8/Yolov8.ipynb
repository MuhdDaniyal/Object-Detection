{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.12-py3-none-any.whl (870 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (3.7.5)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (0.19.1)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch!=2.4.0,>=1.8.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (2.4.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\dany\\appdata\\roaming\\python\\python38\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
      "Collecting pyyaml>=5.3.1\n",
      "  Downloading PyYAML-6.0.2-cp38-cp38-win_amd64.whl (162 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dany\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dany\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dany\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.20.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dany\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dany\\appdata\\roaming\\python\\python38\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dany\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch!=2.4.0,>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch!=2.4.0,>=1.8.0->ultralytics) (1.3.0)\n",
      "Installing collected packages: ultralytics-thop, seaborn, pyyaml, py-cpuinfo, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 pyyaml-6.0.2 seaborn-0.13.2 ultralytics-8.3.12 ultralytics-thop-2.0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dany\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time object detection. Press 'q' to quit.\n",
      "\n",
      "0: 480x640 1 person, 118.1ms\n",
      "Speed: 2.0ms preprocess, 118.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.5ms\n",
      "Speed: 21.7ms preprocess, 122.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 103.5ms\n",
      "Speed: 2.8ms preprocess, 103.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 100.3ms\n",
      "Speed: 0.0ms preprocess, 100.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 99.3ms\n",
      "Speed: 1.7ms preprocess, 99.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 99.1ms\n",
      "Speed: 1.7ms preprocess, 99.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.0ms\n",
      "Speed: 2.5ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 99.6ms\n",
      "Speed: 2.3ms preprocess, 99.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.1ms\n",
      "Speed: 3.0ms preprocess, 95.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.1ms\n",
      "Speed: 2.4ms preprocess, 92.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.7ms\n",
      "Speed: 1.8ms preprocess, 94.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.9ms\n",
      "Speed: 70.7ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.9ms\n",
      "Speed: 2.0ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.1ms\n",
      "Speed: 1.8ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.5ms\n",
      "Speed: 1.8ms preprocess, 90.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.7ms\n",
      "Speed: 2.0ms preprocess, 94.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.7ms\n",
      "Speed: 3.1ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.6ms\n",
      "Speed: 1.0ms preprocess, 90.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.2ms\n",
      "Speed: 1.0ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.6ms\n",
      "Speed: 4.3ms preprocess, 90.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 86.1ms\n",
      "Speed: 1.0ms preprocess, 86.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.6ms\n",
      "Speed: 6.0ms preprocess, 96.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.8ms\n",
      "Speed: 1.0ms preprocess, 92.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.4ms\n",
      "Speed: 3.2ms preprocess, 89.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.0ms\n",
      "Speed: 2.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.9ms\n",
      "Speed: 1.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.5ms\n",
      "Speed: 1.0ms preprocess, 89.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.2ms\n",
      "Speed: 1.0ms preprocess, 94.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.0ms\n",
      "Speed: 1.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.3ms\n",
      "Speed: 2.0ms preprocess, 95.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.0ms\n",
      "Speed: 2.9ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.2ms\n",
      "Speed: 2.0ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.9ms\n",
      "Speed: 1.0ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.6ms\n",
      "Speed: 2.3ms preprocess, 94.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.7ms\n",
      "Speed: 3.1ms preprocess, 95.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.8ms\n",
      "Speed: 1.0ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.2ms\n",
      "Speed: 1.0ms preprocess, 94.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.5ms\n",
      "Speed: 1.0ms preprocess, 92.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 103.4ms\n",
      "Speed: 47.5ms preprocess, 103.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.5ms\n",
      "Speed: 2.0ms preprocess, 95.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.9ms\n",
      "Speed: 2.0ms preprocess, 93.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.8ms\n",
      "Speed: 0.7ms preprocess, 93.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.6ms\n",
      "Speed: 2.2ms preprocess, 92.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.6ms\n",
      "Speed: 1.0ms preprocess, 92.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 97.0ms\n",
      "Speed: 1.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.7ms\n",
      "Speed: 1.7ms preprocess, 90.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.8ms\n",
      "Speed: 1.5ms preprocess, 92.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.3ms\n",
      "Speed: 1.5ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.4ms\n",
      "Speed: 3.4ms preprocess, 90.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 98.0ms\n",
      "Speed: 1.8ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.7ms\n",
      "Speed: 1.0ms preprocess, 84.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.0ms\n",
      "Speed: 2.0ms preprocess, 93.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.9ms\n",
      "Speed: 1.0ms preprocess, 92.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.3ms\n",
      "Speed: 2.0ms preprocess, 92.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.5ms\n",
      "Speed: 1.7ms preprocess, 94.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.9ms\n",
      "Speed: 1.0ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.9ms\n",
      "Speed: 2.0ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.6ms\n",
      "Speed: 2.0ms preprocess, 89.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.2ms\n",
      "Speed: 1.0ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.3ms\n",
      "Speed: 3.0ms preprocess, 96.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 98.4ms\n",
      "Speed: 1.3ms preprocess, 98.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.5ms\n",
      "Speed: 3.0ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.4ms\n",
      "Speed: 1.0ms preprocess, 96.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.8ms\n",
      "Speed: 1.0ms preprocess, 92.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.2ms\n",
      "Speed: 1.9ms preprocess, 81.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.7ms\n",
      "Speed: 1.0ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the YOLOv8 model\n",
    "# You can choose different model sizes: 'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt'\n",
    "model = YOLO('yolov8n.pt')  # Using the Nano version for speed\n",
    "\n",
    "# Initialize video capture\n",
    "# 0 is usually the default webcam. Change the index if you have multiple cameras.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    \n",
    "\n",
    "print(\"Starting real-time object detection. Press 'q' to quit.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Perform object detection\n",
    "        # The model expects images in RGB format, but OpenCV provides them in BGR, so conversion is handled internally\n",
    "        results = model(frame)\n",
    "\n",
    "        # Parse the results\n",
    "        # 'results' is a list; since we're processing one image, we take the first element\n",
    "        result = results[0]\n",
    "\n",
    "        # Render bounding boxes on the frame\n",
    "        annotated_frame = result.plot()\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('YOLOv8 Real-Time Object Detection', annotated_frame)\n",
    "\n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrupted by user.\")\n",
    "\n",
    "finally:\n",
    "    # Release the video capture object and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
