{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have CUDA then run this command otherwise ignore this This is valid for CUDA 11.8 if you have other version then change the last digits according to the version\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2:** OpenCV library for handling video capture and display.\n",
    "\n",
    "**torch:** PyTorch library for tensor computations.\n",
    "\n",
    "**torchvision:** Contains models, datasets, and image transformations for computer vision.\n",
    "\n",
    "**transforms:** For preprocessing the images.\n",
    "\n",
    "**numpy:** For numerical operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you got the SSL certification error while downloading the model Faster RCNN\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the available device: GPU if available, else CPU.\"\"\"\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines whether to use a GPU (if available) or CPU for computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Load the pre-trained Faster R-CNN model.\"\"\"\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    # model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads a pre-trained Faster R-CNN model with a ResNet-50 backbone and Feature Pyramid Network (FPN).\n",
    "\n",
    "Moves the model to the specified device (GPU or CPU).\n",
    "\n",
    "Sets the model to evaluation mode to disable training-specific layers like dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts images from PIL format or NumPy arrays to PyTorch tensors.\n",
    "\n",
    "def get_transform():\n",
    "    \"\"\"Define the image transforms.\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize device if you have CUDA otherwise ignore\n",
    "# device = get_device()\n",
    "# print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faster R-CNN model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model()\n",
    "print(\"Faster R-CNN model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Names: Defines the COCO dataset class names for labeling detected objects.\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A',\n",
    "    'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "    'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "    'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork',\n",
    "    'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
    "    'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet',\n",
    "    'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time object detection with Faster R-CNN. Press 'q' to quit.\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream!!! :)\")\n",
    "    exit\n",
    "\n",
    "print(\"Starting real-time object detection with Faster R-CNN. Press 'q' to quit.\")\n",
    "\n",
    "# Define the transformation\n",
    "transform = get_transform()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the image from BGR to RGB\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Apply the transformations\n",
    "        img_tensor = transform(img).to()\n",
    "\n",
    "        # Add a batch dimension\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Perform inference\n",
    "            outputs = model(img_tensor)\n",
    "\n",
    "        # Process the outputs\n",
    "        # Get the scores, labels, and boxes\n",
    "        scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "        labels = outputs[0]['labels'].detach().cpu().numpy()\n",
    "        boxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "\n",
    "        # Set a confidence threshold\n",
    "        threshold = 0.5\n",
    "        high_conf_indices = np.where(scores >= threshold)[0]\n",
    "\n",
    "        for idx in high_conf_indices:\n",
    "            box = boxes[idx]\n",
    "            label = COCO_INSTANCE_CATEGORY_NAMES[labels[idx]]\n",
    "            score = scores[idx]\n",
    "\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(frame, \n",
    "                            (int(box[0]), int(box[1])), \n",
    "                            (int(box[2]), int(box[3])), \n",
    "                            (0, 255, 0), 2)\n",
    "\n",
    "            # Put the label and score\n",
    "            text = f\"{label}: {score:.2f}\"\n",
    "            cv2.putText(frame, text, \n",
    "                        (int(box[0]), int(box[1])-10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Faster R-CNN Real-Time Object Detection', frame)\n",
    "\n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrupted by user.\")\n",
    "\n",
    "finally:\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captures each frame from the webcam.\n",
    "\n",
    "Converts the frame from BGR (OpenCV format) to RGB (PyTorch format).\n",
    "\n",
    "Applies transformations to convert the image to a tensor.\n",
    "\n",
    "Performs object detection using the Faster R-CNN model.\n",
    "\n",
    "Filters detections based on a confidence threshold (e.g., 0.5).\n",
    "\n",
    "Draws bounding boxes and labels on detected objects.\n",
    "\n",
    "Displays the annotated frame in a window.\n",
    "\n",
    "Allows exiting the loop by pressing the 'q' key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
